//! LiteLLM é›†æˆæ¼”ç¤º
//!
//! å±•ç¤º AgentMem çš„ LiteLLM ç»Ÿä¸€æ¥å£åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§ LLM æä¾›å•†

use agent_mem_llm::providers::litellm::{LiteLLMProvider, LiteLLMMessage, SupportedModel};
use agent_mem_llm::LLMFactory;
use agent_mem_traits::LLMConfig;
use std::env;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    println!("ğŸš€ AgentMem LiteLLM é›†æˆæ¼”ç¤º");
    println!("{}", "=".repeat(50));

    // æ¼”ç¤º 1: ç›´æ¥ä½¿ç”¨ LiteLLM æä¾›å•†
    println!("\nğŸ“‹ æ¼”ç¤º 1: ç›´æ¥ä½¿ç”¨ LiteLLM æä¾›å•†");
    demo_direct_litellm().await?;

    // æ¼”ç¤º 2: é€šè¿‡å·¥å‚æ¨¡å¼ä½¿ç”¨ LiteLLM
    println!("\nğŸ“‹ æ¼”ç¤º 2: é€šè¿‡å·¥å‚æ¨¡å¼ä½¿ç”¨ LiteLLM");
    demo_factory_litellm().await?;

    // æ¼”ç¤º 3: æ”¯æŒçš„æ¨¡å‹å±•ç¤º
    println!("\nğŸ“‹ æ¼”ç¤º 3: æ”¯æŒçš„æ¨¡å‹å±•ç¤º");
    demo_supported_models();

    // æ¼”ç¤º 4: é…ç½®é€‰é¡¹å±•ç¤º
    println!("\nğŸ“‹ æ¼”ç¤º 4: é…ç½®é€‰é¡¹å±•ç¤º");
    demo_configuration_options();

    println!("\nâœ… æ¼”ç¤ºå®Œæˆï¼");
    println!("\nğŸ’¡ æç¤º:");
    println!("   - è®¾ç½®ç›¸åº”çš„ API å¯†é’¥ç¯å¢ƒå˜é‡ä»¥æµ‹è¯•å®é™… LLM è°ƒç”¨");
    println!("   - æ”¯æŒçš„ç¯å¢ƒå˜é‡: OPENAI_API_KEY, ANTHROPIC_API_KEY, DEEPSEEK_API_KEY ç­‰");
    println!("   - LiteLLM æä¾›ç»Ÿä¸€æ¥å£ï¼Œç®€åŒ–å¤š LLM æä¾›å•†é›†æˆ");

    Ok(())
}

/// æ¼”ç¤ºç›´æ¥ä½¿ç”¨ LiteLLM æä¾›å•†
async fn demo_direct_litellm() -> anyhow::Result<()> {
    println!("   ğŸ”§ åˆ›å»º LiteLLM æä¾›å•†...");

    // åˆ›å»º LiteLLM æä¾›å•†
    let provider = LiteLLMProvider::with_model("gpt-3.5-turbo")?;

    println!("   âœ… æä¾›å•†åˆ›å»ºæˆåŠŸ");
    println!("   ğŸ“Š æ¨¡å‹ä¿¡æ¯:");
    println!("      - æ¨¡å‹: {}", provider.get_model());
    println!("      - æœ€å¤§ Token: {:?}", provider.get_max_tokens());

    // å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
    let messages = vec![
        LiteLLMMessage {
            role: "system".to_string(),
            content: "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚".to_string(),
        },
        LiteLLMMessage {
            role: "user".to_string(),
            content: "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½ã€‚".to_string(),
        },
    ];

    // æ£€æŸ¥æ˜¯å¦æœ‰ API å¯†é’¥
    if let Ok(api_key) = env::var("OPENAI_API_KEY") {
        println!("   ğŸ”‘ æ£€æµ‹åˆ° OpenAI API å¯†é’¥ï¼Œå°è¯•å®é™…è°ƒç”¨...");
        
        let provider_with_key = provider.with_api_key(api_key);
        
        match provider_with_key.generate_response(&messages).await {
            Ok(response) => {
                println!("   âœ… LLM å“åº”æˆåŠŸ:");
                println!("      {}", response.chars().take(100).collect::<String>());
                if response.len() > 100 {
                    println!("      ...(å“åº”å·²æˆªæ–­)");
                }
            }
            Err(e) => {
                println!("   âš ï¸  LLM è°ƒç”¨å¤±è´¥: {}", e);
                println!("      è¿™å¯èƒ½æ˜¯ç”±äºç½‘ç»œé—®é¢˜æˆ– API é…é¢é™åˆ¶");
            }
        }
    } else {
        println!("   ğŸ“ æœªæ£€æµ‹åˆ° OPENAI_API_KEYï¼Œè·³è¿‡å®é™… LLM è°ƒç”¨");
        println!("   ğŸ’¡ è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY ä»¥æµ‹è¯•å®é™…è°ƒç”¨");
    }

    Ok(())
}

/// æ¼”ç¤ºé€šè¿‡å·¥å‚æ¨¡å¼ä½¿ç”¨ LiteLLM
async fn demo_factory_litellm() -> anyhow::Result<()> {
    println!("   ğŸ­ é€šè¿‡å·¥å‚æ¨¡å¼åˆ›å»º LiteLLM æä¾›å•†...");

    // åˆ›å»º LLM é…ç½®
    let config = LLMConfig {
        provider: "litellm".to_string(),
        model: "gpt-4".to_string(),
        api_key: env::var("OPENAI_API_KEY").ok(),
        temperature: Some(0.7),
        max_tokens: Some(1000),
        ..Default::default()
    };

    // é€šè¿‡å·¥å‚åˆ›å»ºæä¾›å•†
    match LLMFactory::create_provider(&config) {
        Ok(provider) => {
            println!("   âœ… å·¥å‚åˆ›å»ºæˆåŠŸ");
            
            let model_info = provider.get_model_info();
            println!("   ğŸ“Š æ¨¡å‹ä¿¡æ¯:");
            println!("      - æä¾›å•†: {}", model_info.provider);
            println!("      - æ¨¡å‹: {}", model_info.model);
            println!("      - æœ€å¤§ Token: {}", model_info.max_tokens);
            println!("      - æ”¯æŒæµå¼: {}", model_info.supports_streaming);
            println!("      - æ”¯æŒå‡½æ•°: {}", model_info.supports_functions);

            // å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
            let messages = vec![
                agent_mem_traits::Message {
                    role: agent_mem_traits::MessageRole::System,
                    content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¡¾é—®ã€‚".to_string(),
                    timestamp: None,
                },
                agent_mem_traits::Message {
                    role: agent_mem_traits::MessageRole::User,
                    content: "è¯·è§£é‡Šä»€ä¹ˆæ˜¯ LiteLLMï¼Ÿ".to_string(),
                    timestamp: None,
                },
            ];

            if config.api_key.is_some() {
                println!("   ğŸ”‘ å°è¯•é€šè¿‡å·¥å‚æ¥å£è°ƒç”¨ LLM...");
                
                match provider.generate(&messages).await {
                    Ok(response) => {
                        println!("   âœ… å·¥å‚æ¥å£è°ƒç”¨æˆåŠŸ:");
                        println!("      {}", response.chars().take(100).collect::<String>());
                        if response.len() > 100 {
                            println!("      ...(å“åº”å·²æˆªæ–­)");
                        }
                    }
                    Err(e) => {
                        println!("   âš ï¸  å·¥å‚æ¥å£è°ƒç”¨å¤±è´¥: {}", e);
                    }
                }
            } else {
                println!("   ğŸ“ æœªè®¾ç½® API å¯†é’¥ï¼Œè·³è¿‡å®é™…è°ƒç”¨");
            }
        }
        Err(e) => {
            println!("   âŒ å·¥å‚åˆ›å»ºå¤±è´¥: {}", e);
        }
    }

    Ok(())
}

/// æ¼”ç¤ºæ”¯æŒçš„æ¨¡å‹
fn demo_supported_models() {
    println!("   ğŸ“š LiteLLM æ”¯æŒçš„æ¨¡å‹:");

    let models = vec![
        ("OpenAI", vec![
            SupportedModel::GPT4,
            SupportedModel::GPT4Turbo,
            SupportedModel::GPT35Turbo,
        ]),
        ("Anthropic", vec![
            SupportedModel::Claude3Opus,
            SupportedModel::Claude3Sonnet,
            SupportedModel::Claude3Haiku,
        ]),
        ("AWS Bedrock", vec![
            SupportedModel::BedrockClaude,
            SupportedModel::BedrockTitan,
        ]),
        ("Azure OpenAI", vec![
            SupportedModel::AzureGPT4,
            SupportedModel::AzureGPT35,
        ]),
        ("Google", vec![
            SupportedModel::Gemini15Pro,
            SupportedModel::Gemini15Flash,
        ]),
        ("å…¶ä»–", vec![
            SupportedModel::Groq,
            SupportedModel::Together,
            SupportedModel::Ollama,
        ]),
    ];

    for (provider, provider_models) in models {
        println!("      ğŸ¢ {}:", provider);
        for model in provider_models {
            println!("         - {}", model.as_str());
        }
    }

    println!("   ğŸ’¡ ä½¿ç”¨æ–¹æ³•:");
    println!("      let provider = LiteLLMProvider::with_model(\"gpt-4\")?;");
    println!("      let provider = LiteLLMProvider::with_model(\"claude-3-sonnet-20240229\")?;");
}

/// æ¼”ç¤ºé…ç½®é€‰é¡¹
fn demo_configuration_options() {
    println!("   âš™ï¸  LiteLLM é…ç½®é€‰é¡¹:");
    
    println!("      ğŸ”§ åŸºç¡€é…ç½®:");
    println!("         - model: æ¨¡å‹åç§°");
    println!("         - api_key: API å¯†é’¥");
    println!("         - api_base: è‡ªå®šä¹‰ API åŸºç¡€ URL");
    println!("         - temperature: æ¸©åº¦å‚æ•° (0.0-2.0)");
    println!("         - max_tokens: æœ€å¤§ token æ•°");

    println!("      ğŸ”„ é‡è¯•é…ç½®:");
    println!("         - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°");
    println!("         - backoff_factor: é€€é¿å› å­");
    println!("         - max_backoff: æœ€å¤§é€€é¿æ—¶é—´");

    println!("      ğŸš¦ é€Ÿç‡é™åˆ¶:");
    println!("         - requests_per_minute: æ¯åˆ†é’Ÿè¯·æ±‚æ•°");
    println!("         - tokens_per_minute: æ¯åˆ†é’Ÿ token æ•°");
    println!("         - concurrent_requests: å¹¶å‘è¯·æ±‚æ•°");

    println!("   ğŸ’¡ é…ç½®ç¤ºä¾‹:");
    println!("      ```rust");
    println!("      let config = LiteLLMConfig {{");
    println!("          model: \"gpt-4\".to_string(),");
    println!("          api_key: Some(\"your-api-key\".to_string()),");
    println!("          temperature: Some(0.7),");
    println!("          max_tokens: Some(2000),");
    println!("          ..Default::default()");
    println!("      }};");
    println!("      ```");
}
