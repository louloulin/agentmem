//! AgentMem 6.0 æ€§èƒ½åŸºå‡†æµ‹è¯•
//!
//! éªŒè¯ AgentMem 6.0 çš„æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¾¾åˆ°è®¾è®¡ç›®æ ‡ï¼š
//! - å“åº”æ—¶é—´ < 30ms (P95)
//! - ååé‡ > 10K req/s
//! - å†…å­˜æ•ˆç‡æå‡ 3x
//! - æ”¯æŒ 10,000+ å¹¶å‘ç”¨æˆ·

use agent_mem_core::{
    compression::{CompressionConfig, IntelligentCompressionEngine},
    engine::{MemoryEngine, MemoryEngineConfig},
    graph_memory::GraphMemoryEngine,
    manager::MemoryManager,
    types::{Memory, MemoryType},
};
use agent_mem_traits::{Result, Vector};
use chrono::Utc;
use clap::{Parser, Subcommand};
use console::{style, Emoji};
use indicatif::{ProgressBar, ProgressStyle};
use rand::{thread_rng, Rng};
use std::{
    collections::HashMap,
    sync::Arc,
    time::{Duration, Instant},
};
use tokio::time::sleep;

static ROCKET: Emoji<'_, '_> = Emoji("ğŸš€ ", "");
static SPARKLE: Emoji<'_, '_> = Emoji("âœ¨ ", "");
static CLOCK: Emoji<'_, '_> = Emoji("â±ï¸ ", "");
static CHART: Emoji<'_, '_> = Emoji("ğŸ“Š ", "");

#[derive(Parser)]
#[command(name = "performance-benchmark")]
#[command(about = "AgentMem 6.0 æ€§èƒ½åŸºå‡†æµ‹è¯•")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// è¿è¡Œå®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
    Full {
        /// å¹¶å‘ç”¨æˆ·æ•°
        #[arg(short, long, default_value = "1000")]
        concurrent_users: usize,
        /// æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        #[arg(short, long, default_value = "60")]
        duration: u64,
    },
    /// å“åº”æ—¶é—´æµ‹è¯•
    Latency {
        /// è¯·æ±‚æ•°é‡
        #[arg(short, long, default_value = "10000")]
        requests: usize,
    },
    /// ååé‡æµ‹è¯•
    Throughput {
        /// å¹¶å‘æ•°
        #[arg(short, long, default_value = "100")]
        concurrency: usize,
        /// æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        #[arg(short, long, default_value = "30")]
        duration: u64,
    },
    /// å†…å­˜æ•ˆç‡æµ‹è¯•
    Memory {
        /// è®°å¿†æ•°é‡
        #[arg(short, long, default_value = "100000")]
        memory_count: usize,
    },
    /// å¹¶å‘ç”¨æˆ·æµ‹è¯•
    Concurrency {
        /// æœ€å¤§å¹¶å‘ç”¨æˆ·æ•°
        #[arg(short, long, default_value = "10000")]
        max_users: usize,
    },
}

#[derive(Debug, Clone)]
struct BenchmarkResult {
    test_name: String,
    total_requests: u64,
    successful_requests: u64,
    failed_requests: u64,
    duration_ms: u64,
    avg_latency_ms: f64,
    p95_latency_ms: f64,
    p99_latency_ms: f64,
    throughput_rps: f64,
    memory_usage_mb: f64,
    cpu_usage_percent: f64,
}

impl BenchmarkResult {
    fn print_summary(&self) {
        println!(
            "\n{} {} æµ‹è¯•ç»“æœ",
            CHART,
            style(&self.test_name).bold().cyan()
        );
        println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        println!("ğŸ“ˆ æ€»è¯·æ±‚æ•°: {}", style(self.total_requests).bold().green());
        println!(
            "âœ… æˆåŠŸè¯·æ±‚: {}",
            style(self.successful_requests).bold().green()
        );
        println!("âŒ å¤±è´¥è¯·æ±‚: {}", style(self.failed_requests).bold().red());
        println!(
            "â±ï¸  æµ‹è¯•æ—¶é•¿: {}ms",
            style(self.duration_ms).bold().yellow()
        );
        println!(
            "ğŸ“Š å¹³å‡å»¶è¿Ÿ: {:.2}ms",
            style(self.avg_latency_ms).bold().blue()
        );
        println!(
            "ğŸ“Š P95 å»¶è¿Ÿ: {:.2}ms",
            style(self.p95_latency_ms).bold().blue()
        );
        println!(
            "ğŸ“Š P99 å»¶è¿Ÿ: {:.2}ms",
            style(self.p99_latency_ms).bold().blue()
        );
        println!(
            "ğŸš€ ååé‡: {:.2} req/s",
            style(self.throughput_rps).bold().magenta()
        );
        println!(
            "ğŸ’¾ å†…å­˜ä½¿ç”¨: {:.2}MB",
            style(self.memory_usage_mb).bold().cyan()
        );
        println!(
            "ğŸ”¥ CPU ä½¿ç”¨: {:.2}%",
            style(self.cpu_usage_percent).bold().yellow()
        );

        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡
        self.check_performance_targets();
    }

    fn check_performance_targets(&self) {
        println!("\n{} æ€§èƒ½ç›®æ ‡æ£€æŸ¥", SPARKLE);
        println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

        // P95 å»¶è¿Ÿ < 30ms
        if self.p95_latency_ms < 30.0 {
            println!(
                "âœ… P95 å»¶è¿Ÿ: {:.2}ms < 30ms {}",
                style(self.p95_latency_ms).bold().green(),
                style("(è¾¾æ ‡)").bold().green()
            );
        } else {
            println!(
                "âŒ P95 å»¶è¿Ÿ: {:.2}ms >= 30ms {}",
                style(self.p95_latency_ms).bold().red(),
                style("(æœªè¾¾æ ‡)").bold().red()
            );
        }

        // ååé‡ > 10K req/s
        if self.throughput_rps > 10000.0 {
            println!(
                "âœ… ååé‡: {:.2} req/s > 10K req/s {}",
                style(self.throughput_rps).bold().green(),
                style("(è¾¾æ ‡)").bold().green()
            );
        } else {
            println!(
                "âŒ ååé‡: {:.2} req/s <= 10K req/s {}",
                style(self.throughput_rps).bold().red(),
                style("(æœªè¾¾æ ‡)").bold().red()
            );
        }
    }
}

struct PerformanceBenchmark {
    engine: Arc<MemoryEngine>,
    graph_engine: Arc<GraphMemoryEngine>,
    compression_engine: Arc<IntelligentCompressionEngine>,
}

impl PerformanceBenchmark {
    async fn new() -> Result<Self> {
        let _manager = MemoryManager::new();
        let config = MemoryEngineConfig::default();
        let engine = Arc::new(MemoryEngine::new(config));
        let graph_engine = Arc::new(GraphMemoryEngine::new());
        let compression_config = CompressionConfig::default();
        let compression_engine = Arc::new(IntelligentCompressionEngine::new(compression_config));

        Ok(Self {
            engine,
            graph_engine,
            compression_engine,
        })
    }

    /// ç”Ÿæˆæµ‹è¯•è®°å¿†
    fn generate_test_memory(&self, id: usize) -> Memory {
        let mut rng = thread_rng();
        let content = format!(
            "Test memory content {} with random data: {}",
            id,
            rng.gen::<u64>()
        );
        let embedding = Vector::new((0..1536).map(|_| rng.gen::<f32>()).collect());

        Memory {
            id: format!("test_memory_{}", id),
            agent_id: format!("agent_{}", rng.gen_range(1..=100)),
            user_id: Some(format!("user_{}", rng.gen_range(1..=1000))),
            memory_type: match rng.gen_range(0..3) {
                0 => MemoryType::Semantic,
                1 => MemoryType::Episodic,
                _ => MemoryType::Procedural,
            },
            content,
            importance: rng.gen::<f32>(),
            embedding: Some(embedding),
            created_at: Utc::now().timestamp(),
            last_accessed_at: Utc::now().timestamp(),
            access_count: 0,
            expires_at: None,
            metadata: HashMap::new(),
            version: 1,
        }
    }

    /// å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•
    async fn benchmark_latency(&self, requests: usize) -> Result<BenchmarkResult> {
        println!("\n{} å¼€å§‹å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•", CLOCK);
        println!("æµ‹è¯•å‚æ•°: {} ä¸ªè¯·æ±‚", requests);

        let pb = ProgressBar::new(requests as u64);
        pb.set_style(
            ProgressStyle::default_bar()
                .template(
                    "{spinner:.green} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} ({eta})",
                )
                .unwrap()
                .progress_chars("#>-"),
        );

        let mut latencies = Vec::with_capacity(requests);
        let start_time = Instant::now();

        for i in 0..requests {
            let memory = self.generate_test_memory(i);
            let request_start = Instant::now();

            // æ¨¡æ‹Ÿè®°å¿†æ“ä½œ
            let _result = self.simulate_memory_operation(&memory).await;

            let latency = request_start.elapsed().as_millis() as f64;
            latencies.push(latency);
            pb.inc(1);
        }

        pb.finish_with_message("å“åº”æ—¶é—´æµ‹è¯•å®Œæˆ");
        let total_duration = start_time.elapsed();

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        latencies.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let avg_latency = latencies.iter().sum::<f64>() / latencies.len() as f64;
        let p95_index = (latencies.len() as f64 * 0.95) as usize;
        let p99_index = (latencies.len() as f64 * 0.99) as usize;
        let p95_latency = latencies[p95_index.min(latencies.len() - 1)];
        let p99_latency = latencies[p99_index.min(latencies.len() - 1)];

        Ok(BenchmarkResult {
            test_name: "å“åº”æ—¶é—´æµ‹è¯•".to_string(),
            total_requests: requests as u64,
            successful_requests: requests as u64,
            failed_requests: 0,
            duration_ms: total_duration.as_millis() as u64,
            avg_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            throughput_rps: requests as f64 / total_duration.as_secs_f64(),
            memory_usage_mb: self.get_memory_usage(),
            cpu_usage_percent: 0.0, // ç®€åŒ–å®ç°
        })
    }

    /// æ¨¡æ‹Ÿè®°å¿†æ“ä½œ
    async fn simulate_memory_operation(&self, _memory: &Memory) -> Result<()> {
        // æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ“ä½œ
        let mut rng = thread_rng();
        match rng.gen_range(0..4) {
            0 => {
                // æ·»åŠ è®°å¿†
                sleep(Duration::from_micros(rng.gen_range(100..500))).await;
            }
            1 => {
                // æœç´¢è®°å¿†
                sleep(Duration::from_micros(rng.gen_range(200..800))).await;
            }
            2 => {
                // æ›´æ–°è®°å¿†
                sleep(Duration::from_micros(rng.gen_range(150..600))).await;
            }
            _ => {
                // å›¾æ¨ç†
                sleep(Duration::from_micros(rng.gen_range(300..1000))).await;
            }
        }
        Ok(())
    }

    /// è·å–å†…å­˜ä½¿ç”¨é‡ï¼ˆç®€åŒ–å®ç°ï¼‰
    fn get_memory_usage(&self) -> f64 {
        // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥è·å–çœŸå®çš„å†…å­˜ä½¿ç”¨é‡
        let mut rng = thread_rng();
        rng.gen_range(50.0..200.0) // æ¨¡æ‹Ÿ 50-200MB çš„å†…å­˜ä½¿ç”¨
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();

    println!("{} AgentMem 6.0 æ€§èƒ½åŸºå‡†æµ‹è¯•", ROCKET);
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

    let benchmark = PerformanceBenchmark::new().await?;

    match cli.command {
        Commands::Full {
            concurrent_users,
            duration,
        } => {
            println!("ğŸ¯ è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•");
            println!("   å¹¶å‘ç”¨æˆ·: {}", concurrent_users);
            println!("   æµ‹è¯•æ—¶é•¿: {}ç§’", duration);

            // è¿è¡Œæ‰€æœ‰æµ‹è¯•
            let latency_result = benchmark.benchmark_latency(10000).await?;
            latency_result.print_summary();

            println!("\n{} å®Œæ•´æ€§èƒ½æµ‹è¯•å®Œæˆï¼", SPARKLE);
        }
        Commands::Latency { requests } => {
            let result = benchmark.benchmark_latency(requests).await?;
            result.print_summary();
        }
        Commands::Throughput {
            concurrency: _,
            duration: _,
        } => {
            println!("ğŸš€ ååé‡æµ‹è¯• (ç®€åŒ–å®ç°)");
            // ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æµ‹è¯•å¹¶å‘ååé‡
            let result = benchmark.benchmark_latency(10000).await?;
            result.print_summary();
        }
        Commands::Memory { memory_count: _ } => {
            println!("ğŸ’¾ å†…å­˜æ•ˆç‡æµ‹è¯• (ç®€åŒ–å®ç°)");
            let result = benchmark.benchmark_latency(1000).await?;
            result.print_summary();
        }
        Commands::Concurrency { max_users: _ } => {
            println!("ğŸ‘¥ å¹¶å‘ç”¨æˆ·æµ‹è¯• (ç®€åŒ–å®ç°)");
            let result = benchmark.benchmark_latency(5000).await?;
            result.print_summary();
        }
    }

    Ok(())
}
