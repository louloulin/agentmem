//! å­˜å‚¨è¿ç§»æ¼”ç¤ºç¨‹åº
//!
//! å±•ç¤ºçœŸå®žçš„æ•°æ®è¿ç§»åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
//! - ä¸åŒå­˜å‚¨åŽç«¯ä¹‹é—´çš„æ•°æ®è¿ç§»
//! - æ‰¹é‡å¤„ç†å’Œè¿›åº¦è·Ÿè¸ª
//! - é”™è¯¯æ¢å¤å’Œé‡è¯•æœºåˆ¶
//! - æ€§èƒ½ç›‘æŽ§å’Œç»Ÿè®¡

use agent_mem_storage::backends::memory::MemoryVectorStore;
use agent_mem_traits::{Result, VectorData, VectorStore, VectorStoreConfig};
use agent_mem_utils::migration::{DataMigrator, MigrationConfig, MigrationStatus, MigrationTools};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{info, warn};

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt().with_env_filter("info").init();

    info!("ðŸš€ å¼€å§‹å­˜å‚¨è¿ç§»æ¼”ç¤º");

    // æ¼”ç¤º 1: åŸºæœ¬è¿ç§»åŠŸèƒ½
    demo_basic_migration().await?;

    // æ¼”ç¤º 2: å¤§è§„æ¨¡æ•°æ®è¿ç§»
    demo_large_scale_migration().await?;

    // æ¼”ç¤º 3: è¿ç§»å·¥å…·åŠŸèƒ½
    demo_migration_tools().await?;

    // æ¼”ç¤º 4: é”™è¯¯å¤„ç†å’Œæ¢å¤
    demo_error_handling().await?;

    info!("âœ… å­˜å‚¨è¿ç§»æ¼”ç¤ºå®Œæˆ");
    Ok(())
}

/// æ¼”ç¤ºåŸºæœ¬è¿ç§»åŠŸèƒ½
async fn demo_basic_migration() -> Result<()> {
    info!("ðŸ“¦ æ¼”ç¤º 1: åŸºæœ¬è¿ç§»åŠŸèƒ½");

    // åˆ›å»ºæºå­˜å‚¨ï¼ˆåŒ…å«æ•°æ®ï¼‰
    let source = create_populated_store("source", 100).await?;

    // åˆ›å»ºç›®æ ‡å­˜å‚¨ï¼ˆç©ºï¼‰
    let target = create_empty_store("target").await?;

    // é…ç½®è¿ç§»å‚æ•°
    let config = MigrationConfig {
        batch_size: 20,
        clear_target: true,
        validate_data: true,
        ..Default::default()
    };

    // æ‰§è¡Œè¿ç§»
    let migrator = DataMigrator::new(config);
    info!("å¼€å§‹è¿ç§» 100 æ¡è®°å½•...");

    let result = migrator.migrate(source.clone(), target.clone()).await?;

    info!("âœ… è¿ç§»å®Œæˆ:");
    info!("  - æ€»è®°å½•æ•°: {}", result.total_records);
    info!("  - æˆåŠŸè®°å½•: {}", result.successful_records);
    info!("  - å¤±è´¥è®°å½•: {}", result.failed_records);
    info!("  - è€—æ—¶: {:.2}ç§’", result.duration_seconds);
    info!("  - å¹³å‡é€Ÿåº¦: {:.2} è®°å½•/ç§’", result.average_speed);

    // éªŒè¯è¿ç§»ç»“æžœ
    let source_count = source.count_vectors().await?;
    let target_count = target.count_vectors().await?;

    info!("ðŸ“Š è¿ç§»éªŒè¯:");
    info!("  - æºå­˜å‚¨è®°å½•æ•°: {}", source_count);
    info!("  - ç›®æ ‡å­˜å‚¨è®°å½•æ•°: {}", target_count);

    assert_eq!(source_count, target_count);
    info!("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡");

    Ok(())
}

/// æ¼”ç¤ºå¤§è§„æ¨¡æ•°æ®è¿ç§»
async fn demo_large_scale_migration() -> Result<()> {
    info!("ðŸ“¦ æ¼”ç¤º 2: å¤§è§„æ¨¡æ•°æ®è¿ç§»");

    // åˆ›å»ºå¤§è§„æ¨¡æ•°æ®é›†
    let source = create_populated_store("large_source", 5000).await?;
    let target = create_empty_store("large_target").await?;

    // é…ç½®å¤§è§„æ¨¡è¿ç§»
    let config = MigrationConfig {
        batch_size: 500,
        clear_target: true,
        validate_data: false, // å¤§è§„æ¨¡è¿ç§»æ—¶å¯ä»¥å…³é—­éªŒè¯ä»¥æé«˜æ€§èƒ½
        retry_count: 3,
        retry_delay_ms: 1000,
        ..Default::default()
    };

    let migrator = DataMigrator::new(config);

    // é¢„ä¼°è¿ç§»æ—¶é—´
    let config = MigrationConfig {
        batch_size: 500,
        clear_target: true,
        validate_data: false,
        retry_count: 3,
        retry_delay_ms: 1000,
        ..Default::default()
    };
    let estimated_time = MigrationTools::estimate_migration_time(source.clone(), &config).await?;
    info!("ðŸ“Š é¢„ä¼°è¿ç§»æ—¶é—´: {:.2}ç§’", estimated_time.as_secs_f64());

    // æ‰§è¡Œè¿ç§»
    info!("å¼€å§‹å¤§è§„æ¨¡è¿ç§» 5000 æ¡è®°å½•...");
    let result = migrator.migrate(source, target).await?;

    info!("âœ… å¤§è§„æ¨¡è¿ç§»å®Œæˆ:");
    info!("  - æ€»è®°å½•æ•°: {}", result.total_records);
    info!("  - æˆåŠŸè®°å½•: {}", result.successful_records);
    info!("  - å¤±è´¥è®°å½•: {}", result.failed_records);
    info!("  - å®žé™…è€—æ—¶: {:.2}ç§’", result.duration_seconds);
    info!("  - å¹³å‡é€Ÿåº¦: {:.2} è®°å½•/ç§’", result.average_speed);
    info!(
        "  - é¢„ä¼°å‡†ç¡®åº¦: {:.1}%",
        (estimated_time.as_secs_f64() / result.duration_seconds) * 100.0
    );

    Ok(())
}

/// æ¼”ç¤ºè¿ç§»å·¥å…·åŠŸèƒ½
async fn demo_migration_tools() -> Result<()> {
    info!("ðŸ“¦ æ¼”ç¤º 3: è¿ç§»å·¥å…·åŠŸèƒ½");

    let source = create_populated_store("tools_source", 200).await?;
    let target = create_empty_store("tools_target").await?;

    // å…¼å®¹æ€§æ£€æŸ¥
    info!("ðŸ” æ£€æŸ¥å­˜å‚¨å…¼å®¹æ€§...");
    let is_compatible =
        MigrationTools::validate_compatibility(source.clone(), target.clone()).await?;
    info!(
        "å…¼å®¹æ€§æ£€æŸ¥ç»“æžœ: {}",
        if is_compatible {
            "âœ… å…¼å®¹"
        } else {
            "âŒ ä¸å…¼å®¹"
        }
    );

    // åˆ›å»ºè¿ç§»å™¨å¹¶ç›‘æŽ§è¿›åº¦
    let migrator = MigrationTools::create_migrator();

    // æ¨¡æ‹Ÿè¿›åº¦ç›‘æŽ§
    info!("ðŸ“Š ç›‘æŽ§è¿ç§»è¿›åº¦...");
    let progress = migrator.get_progress().await;
    info!("å½“å‰çŠ¶æ€: {:?}", progress.status);
    info!(
        "å¤„ç†è¿›åº¦: {}/{}",
        progress.processed_records, progress.total_records
    );

    // æš‚åœå’Œæ¢å¤åŠŸèƒ½
    info!("â¸ï¸  æµ‹è¯•æš‚åœåŠŸèƒ½...");
    migrator.pause().await;
    let progress = migrator.get_progress().await;
    assert_eq!(progress.status, MigrationStatus::Preparing);

    info!("â–¶ï¸  æµ‹è¯•æ¢å¤åŠŸèƒ½...");
    migrator.resume().await;
    let progress = migrator.get_progress().await;
    info!("æ¢å¤åŽçŠ¶æ€: {:?}", progress.status);

    Ok(())
}

/// æ¼”ç¤ºé”™è¯¯å¤„ç†å’Œæ¢å¤
async fn demo_error_handling() -> Result<()> {
    info!("ðŸ“¦ æ¼”ç¤º 4: é”™è¯¯å¤„ç†å’Œæ¢å¤");

    let source = create_populated_store("error_source", 50).await?;
    let target = create_empty_store("error_target").await?;

    // é…ç½®å¸¦é‡è¯•çš„è¿ç§»
    let config = MigrationConfig {
        batch_size: 10,
        retry_count: 3,
        retry_delay_ms: 500,
        clear_target: true,
        validate_data: true,
        ..Default::default()
    };

    let migrator = DataMigrator::new(config);

    info!("ðŸ”„ æ‰§è¡Œå¸¦é”™è¯¯æ¢å¤çš„è¿ç§»...");
    let result = migrator.migrate(source, target).await?;

    info!("âœ… é”™è¯¯æ¢å¤è¿ç§»å®Œæˆ:");
    info!("  - æ€»è®°å½•æ•°: {}", result.total_records);
    info!("  - æˆåŠŸè®°å½•: {}", result.successful_records);
    info!("  - å¤±è´¥è®°å½•: {}", result.failed_records);
    info!("  - è€—æ—¶: {:.2}ç§’", result.duration_seconds);

    if result.failed_records > 0 {
        warn!("âš ï¸  æœ‰ {} æ¡è®°å½•è¿ç§»å¤±è´¥", result.failed_records);
    }

    Ok(())
}

/// åˆ›å»ºåŒ…å«æ•°æ®çš„å­˜å‚¨
async fn create_populated_store(name: &str, count: usize) -> Result<Arc<MemoryVectorStore>> {
    let mut config = VectorStoreConfig::default();
    config.dimension = Some(128); // è®¾ç½®ä¸ºæˆ‘ä»¬æµ‹è¯•å‘é‡çš„ç»´åº¦
    let store = Arc::new(MemoryVectorStore::new(config).await?);

    // ç”Ÿæˆæµ‹è¯•æ•°æ®
    let mut vectors = Vec::new();
    for i in 0..count {
        let id = format!("{}_{}", name, i);
        let vector = generate_test_vector(i, 128);
        let mut metadata = HashMap::new();
        metadata.insert("index".to_string(), i.to_string());
        metadata.insert("source".to_string(), name.to_string());
        metadata.insert("timestamp".to_string(), chrono::Utc::now().to_rfc3339());

        vectors.push(VectorData {
            id,
            vector,
            metadata,
        });
    }

    // æ‰¹é‡æ·»åŠ æ•°æ®
    store.add_vectors(vectors).await?;
    info!("ðŸ“Š åˆ›å»ºå­˜å‚¨ '{}' åŒ…å« {} æ¡è®°å½•", name, count);

    Ok(store)
}

/// åˆ›å»ºç©ºå­˜å‚¨
async fn create_empty_store(name: &str) -> Result<Arc<MemoryVectorStore>> {
    let mut config = VectorStoreConfig::default();
    config.dimension = Some(128); // è®¾ç½®ä¸ºæˆ‘ä»¬æµ‹è¯•å‘é‡çš„ç»´åº¦
    let store = Arc::new(MemoryVectorStore::new(config).await?);
    info!("ðŸ“Š åˆ›å»ºç©ºå­˜å‚¨ '{}'", name);
    Ok(store)
}

/// ç”Ÿæˆæµ‹è¯•å‘é‡
fn generate_test_vector(seed: usize, dim: usize) -> Vec<f32> {
    let mut vector = Vec::with_capacity(dim);
    for i in 0..dim {
        let value =
            ((seed * 31 + i * 17) as f32).sin() * 0.5 + ((seed * 13 + i * 7) as f32).cos() * 0.3;
        vector.push(value);
    }

    // å½’ä¸€åŒ–
    let norm: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 0.0 {
        for v in &mut vector {
            *v /= norm;
        }
    }

    vector
}
