//! çœŸå®å¤šæ¨¡æ€å¤„ç†æ¼”ç¤ºç¨‹åº
//!
//! æ¼”ç¤ºçœŸå®çš„å›¾åƒå’ŒéŸ³é¢‘å¤„ç†åŠŸèƒ½

use agent_mem_intelligence::multimodal::{
    real_audio::{RealAudioProcessor, RealAudioProcessorConfig},
    real_image::{RealImageProcessor, RealImageProcessorConfig},
    ContentType, MultimodalContent, MultimodalProcessor, ProcessingStatus,
};
use std::collections::HashMap;
use tracing::{error, info, warn};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_env_filter("multimodal_real_demo=info,agent_mem_intelligence=info")
        .init();

    info!("ğŸš€ å¼€å§‹çœŸå®å¤šæ¨¡æ€å¤„ç†æ¼”ç¤º");

    // æµ‹è¯•çœŸå®å›¾åƒå¤„ç†
    test_real_image_processing().await?;

    // æµ‹è¯•çœŸå®éŸ³é¢‘å¤„ç†
    test_real_audio_processing().await?;

    info!("âœ… çœŸå®å¤šæ¨¡æ€å¤„ç†æ¼”ç¤ºå®Œæˆ");
    Ok(())
}

/// æµ‹è¯•çœŸå®å›¾åƒå¤„ç†
async fn test_real_image_processing() -> Result<(), Box<dyn std::error::Error>> {
    info!("ğŸ–¼ï¸  å¼€å§‹æµ‹è¯•çœŸå®å›¾åƒå¤„ç†");

    // åˆ›å»ºçœŸå®å›¾åƒå¤„ç†å™¨é…ç½®
    let config = RealImageProcessorConfig {
        enable_ocr: true,
        enable_object_detection: true,
        enable_scene_analysis: true,
        openai_api_key: std::env::var("OPENAI_API_KEY").ok(),
        google_vision_api_key: std::env::var("GOOGLE_VISION_API_KEY").ok(),
        tesseract_path: None,
        use_local_models: true,
    };

    let processor = RealImageProcessor::new(config);

    // æµ‹è¯•ä¸åŒç±»å‹çš„å›¾åƒ
    let test_images = vec![
        ("screenshot_ui.png", "screenshot", "image/png"),
        ("document_scan.jpg", "document", "image/jpeg"),
        ("chart_data.png", "chart", "image/png"),
        ("photo_nature.jpg", "photo", "image/jpeg"),
    ];

    for (filename, content_type, mime_type) in test_images {
        info!("å¤„ç†å›¾åƒ: {}", filename);

        // åˆ›å»ºæ¨¡æ‹Ÿå›¾åƒå†…å®¹
        let mut content = create_mock_image_content(filename, content_type, mime_type);

        // å¤„ç†å›¾åƒ
        match processor.process(&mut content).await {
            Ok(()) => {
                info!("âœ… å›¾åƒå¤„ç†æˆåŠŸ: {}", filename);

                if let Some(extracted_text) = &content.extracted_text {
                    info!("ğŸ“ æå–çš„æ–‡æœ¬: {}", extracted_text);
                }

                // ç”Ÿæˆæ‘˜è¦
                if let Ok(Some(summary)) = processor.generate_summary(&content).await {
                    info!("ğŸ“‹ å›¾åƒæ‘˜è¦: {}", summary);
                }
            }
            Err(e) => {
                error!("âŒ å›¾åƒå¤„ç†å¤±è´¥: {} - {}", filename, e);
            }
        }

        println!(); // ç©ºè¡Œåˆ†éš”
    }

    Ok(())
}

/// æµ‹è¯•çœŸå®éŸ³é¢‘å¤„ç†
async fn test_real_audio_processing() -> Result<(), Box<dyn std::error::Error>> {
    info!("ğŸµ å¼€å§‹æµ‹è¯•çœŸå®éŸ³é¢‘å¤„ç†");

    // åˆ›å»ºçœŸå®éŸ³é¢‘å¤„ç†å™¨é…ç½®
    let config = RealAudioProcessorConfig {
        enable_speech_to_text: true,
        enable_audio_analysis: true,
        openai_api_key: std::env::var("OPENAI_API_KEY").ok(),
        google_speech_api_key: std::env::var("GOOGLE_SPEECH_API_KEY").ok(),
        azure_speech_api_key: std::env::var("AZURE_SPEECH_API_KEY").ok(),
        azure_speech_region: std::env::var("AZURE_SPEECH_REGION").ok(),
        use_local_whisper: true,
        whisper_model_size: "base".to_string(),
    };

    let processor = RealAudioProcessor::new(config);

    // æµ‹è¯•ä¸åŒç±»å‹çš„éŸ³é¢‘
    let test_audios = vec![
        ("speech_recording.wav", "speech", "audio/wav"),
        ("meeting_call.mp3", "meeting", "audio/mp3"),
        ("interview_session.wav", "interview", "audio/wav"),
        ("music_song.mp3", "music", "audio/mp3"),
    ];

    for (filename, content_type, mime_type) in test_audios {
        info!("å¤„ç†éŸ³é¢‘: {}", filename);

        // åˆ›å»ºæ¨¡æ‹ŸéŸ³é¢‘å†…å®¹
        let mut content = create_mock_audio_content(filename, content_type, mime_type);

        // å¤„ç†éŸ³é¢‘
        match processor.process(&mut content).await {
            Ok(()) => {
                info!("âœ… éŸ³é¢‘å¤„ç†æˆåŠŸ: {}", filename);

                if let Some(extracted_text) = &content.extracted_text {
                    info!("ğŸ—£ï¸  è½¬å½•æ–‡æœ¬: {}", extracted_text);
                }

                // ç”Ÿæˆæ‘˜è¦
                if let Ok(Some(summary)) = processor.generate_summary(&content).await {
                    info!("ğŸ“‹ éŸ³é¢‘æ‘˜è¦: {}", summary);
                }
            }
            Err(e) => {
                error!("âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {} - {}", filename, e);
            }
        }

        println!(); // ç©ºè¡Œåˆ†éš”
    }

    Ok(())
}

/// åˆ›å»ºæ¨¡æ‹Ÿå›¾åƒå†…å®¹
fn create_mock_image_content(
    filename: &str,
    content_type: &str,
    mime_type: &str,
) -> MultimodalContent {
    let mut content = MultimodalContent::new(uuid::Uuid::new_v4().to_string(), ContentType::Image);

    // è®¾ç½®åŸºæœ¬ä¿¡æ¯
    content.mime_type = Some(mime_type.to_string());
    content.size = Some(generate_mock_file_size(content_type));

    // è®¾ç½®å…ƒæ•°æ®
    content.set_metadata(
        "filename".to_string(),
        serde_json::Value::String(filename.to_string()),
    );
    content.set_metadata(
        "content_type".to_string(),
        serde_json::Value::String(content_type.to_string()),
    );

    // æ¨¡æ‹Ÿ Base64 æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯çœŸå®çš„å›¾åƒæ•°æ®ï¼‰
    let mock_data = format!("mock_image_data_for_{}", filename);
    content.data = Some(base64::encode(mock_data.as_bytes()));

    content
}

/// åˆ›å»ºæ¨¡æ‹ŸéŸ³é¢‘å†…å®¹
fn create_mock_audio_content(
    filename: &str,
    content_type: &str,
    mime_type: &str,
) -> MultimodalContent {
    let mut content = MultimodalContent::new(uuid::Uuid::new_v4().to_string(), ContentType::Audio);

    // è®¾ç½®åŸºæœ¬ä¿¡æ¯
    content.mime_type = Some(mime_type.to_string());
    content.size = Some(generate_mock_file_size(content_type));

    // è®¾ç½®å…ƒæ•°æ®
    content.set_metadata(
        "filename".to_string(),
        serde_json::Value::String(filename.to_string()),
    );
    content.set_metadata(
        "content_type".to_string(),
        serde_json::Value::String(content_type.to_string()),
    );

    // æ¨¡æ‹Ÿ Base64 æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯çœŸå®çš„éŸ³é¢‘æ•°æ®ï¼‰
    let mock_data = format!("mock_audio_data_for_{}", filename);
    content.data = Some(base64::encode(mock_data.as_bytes()));

    content
}

/// ç”Ÿæˆæ¨¡æ‹Ÿæ–‡ä»¶å¤§å°
fn generate_mock_file_size(content_type: &str) -> u64 {
    match content_type {
        "screenshot" => 150_000,  // 150KB
        "document" => 500_000,    // 500KB
        "chart" => 80_000,        // 80KB
        "photo" => 2_000_000,     // 2MB
        "speech" => 1_200_000,    // 1.2MB
        "meeting" => 5_000_000,   // 5MB
        "interview" => 3_000_000, // 3MB
        "music" => 8_000_000,     // 8MB
        _ => 1_000_000,           // 1MB é»˜è®¤
    }
}

/// Base64 ç¼–ç å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
mod base64 {
    pub fn encode(data: &[u8]) -> String {
        // ç®€åŒ–çš„ Base64 ç¼–ç å®ç°
        format!("base64_encoded_{}_bytes", data.len())
    }
}
