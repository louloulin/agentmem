//! Claude (Anthropic) LLM provider implementation
//! 
//! Provides integration with Anthropic's Claude models including
//! Claude-3, Claude-3.5, and Claude-2 series.

use agent_mem_traits::LLMConfig;
use agent_mem_traits::{Result, AgentMemError, Message, MessageRole};
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};

use tracing::{debug, error, info};

/// Claude API request structure
#[derive(Debug, Serialize)]
struct ClaudeRequest {
    model: String,
    max_tokens: u32,
    messages: Vec<ClaudeMessage>,
    #[serde(skip_serializing_if = "Option::is_none")]
    system: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    top_p: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    top_k: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    stop_sequences: Option<Vec<String>>,
}

/// Claude message structure
#[derive(Debug, Serialize, Deserialize)]
struct ClaudeMessage {
    role: String,
    content: String,
}

/// Claude API response structure
#[derive(Debug, Deserialize)]
struct ClaudeResponse {
    id: String,
    #[serde(rename = "type")]
    response_type: String,
    role: String,
    content: Vec<ClaudeContent>,
    model: String,
    stop_reason: Option<String>,
    stop_sequence: Option<String>,
    usage: ClaudeUsage,
}

/// Claude content structure
#[derive(Debug, Deserialize)]
struct ClaudeContent {
    #[serde(rename = "type")]
    content_type: String,
    text: String,
}

/// Claude usage statistics
#[derive(Debug, Deserialize)]
struct ClaudeUsage {
    input_tokens: u32,
    output_tokens: u32,
}

/// Claude error response
#[derive(Debug, Deserialize)]
struct ClaudeError {
    #[serde(rename = "type")]
    error_type: String,
    message: String,
}

/// Claude LLM provider
pub struct ClaudeProvider {
    config: LLMConfig,
    client: Client,
    api_key: String,
    base_url: String,
}

impl ClaudeProvider {
    /// Create a new Claude provider
    pub fn new(config: LLMConfig) -> Result<Self> {
        let api_key = config.api_key.clone()
            .ok_or_else(|| AgentMemError::config_error("Claude API key is required"))?;
        
        let client = Client::builder()
            .timeout(std::time::Duration::from_secs(30)) // Default timeout
            .build()
            .map_err(|e| AgentMemError::network_error(&format!("Failed to create HTTP client: {}", e)))?;
        
        let base_url = config.base_url.clone()
            .unwrap_or_else(|| "https://api.anthropic.com".to_string());
        
        Ok(Self {
            config,
            client,
            api_key,
            base_url,
        })
    }
    
    /// Get available Claude models
    pub fn available_models() -> Vec<&'static str> {
        vec![
            "claude-3-5-sonnet-20241022",
            "claude-3-5-sonnet-20240620",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
            "claude-2.1",
            "claude-2.0",
            "claude-instant-1.2",
        ]
    }
    
    /// Convert AgentMem message to Claude message
    fn convert_message(&self, message: &Message) -> ClaudeMessage {
        let role = match message.role {
            MessageRole::System => "system",
            MessageRole::User => "user",
            MessageRole::Assistant => "assistant",
        };
        
        ClaudeMessage {
            role: role.to_string(),
            content: message.content.clone(),
        }
    }
    
    /// Build Claude API request
    fn build_request(&self, messages: &[Message]) -> Result<ClaudeRequest> {
        let mut claude_messages = Vec::new();
        let mut system_message = None;
        
        // Separate system message from conversation messages
        for message in messages {
            match message.role {
                MessageRole::System => {
                    system_message = Some(message.content.clone());
                }
                _ => {
                    claude_messages.push(self.convert_message(message));
                }
            }
        }
        
        let request = ClaudeRequest {
            model: self.config.model.clone(),
            max_tokens: self.config.max_tokens.unwrap_or(4096),
            messages: claude_messages,
            system: system_message,
            temperature: self.config.temperature,
            top_p: self.config.top_p,
            top_k: None, // Not available in LLMConfig
            stop_sequences: None, // Not available in LLMConfig
        };
        
        Ok(request)
    }
    
    /// Make API request to Claude
    async fn make_request(&self, request: &ClaudeRequest) -> Result<ClaudeResponse> {
        debug!("Making Claude API request to model: {}", request.model);
        
        let response = self.client
            .post(&format!("{}/v1/messages", self.base_url))
            .header("Content-Type", "application/json")
            .header("x-api-key", &self.api_key)
            .header("anthropic-version", "2023-06-01")
            .json(request)
            .send()
            .await
            .map_err(|e| AgentMemError::network_error(&format!("Claude API request failed: {}", e)))?;
        
        let status = response.status();
        let response_text = response.text().await
            .map_err(|e| AgentMemError::network_error(&format!("Failed to read response: {}", e)))?;
        
        if status.is_success() {
            serde_json::from_str(&response_text)
                .map_err(|e| AgentMemError::parsing_error(&format!("Failed to parse Claude response: {}", e)))
        } else {
            // Try to parse error response
            if let Ok(error) = serde_json::from_str::<ClaudeError>(&response_text) {
                error!("Claude API error: {} - {}", error.error_type, error.message);
                Err(AgentMemError::llm_error(&format!("Claude API error: {}", error.message)))
            } else {
                error!("Claude API error (status {}): {}", status, response_text);
                Err(AgentMemError::llm_error(&format!("Claude API error: HTTP {}", status)))
            }
        }
    }
}

#[async_trait]
impl crate::LLMProvider for ClaudeProvider {
    async fn generate(&self, messages: &[Message]) -> Result<String> {
        info!("Generating response using Claude model: {}", self.config.model);
        
        let request = self.build_request(messages)?;
        let response = self.make_request(&request).await?;
        
        // Extract text from response content
        let text = response.content
            .into_iter()
            .filter(|content| content.content_type == "text")
            .map(|content| content.text)
            .collect::<Vec<_>>()
            .join("\n");
        
        if text.is_empty() {
            return Err(AgentMemError::llm_error("Claude returned empty response"));
        }
        
        info!("Claude response generated successfully (tokens: input={}, output={})", 
              response.usage.input_tokens, response.usage.output_tokens);
        
        Ok(text)
    }
    
    async fn generate_stream(&self, messages: &[Message]) -> Result<Box<dyn futures::Stream<Item = Result<String>> + Send + Unpin>> {
        // For now, fall back to non-streaming
        let response = self.generate(messages).await?;
        let stream = futures::stream::once(async move { Ok(response) });
        Ok(Box::new(Box::pin(stream)))
    }
    
    fn get_model_info(&self) -> agent_mem_traits::ModelInfo {
        agent_mem_traits::ModelInfo {
            provider: "anthropic".to_string(),
            model: self.config.model.clone(),
            max_tokens: self.config.max_tokens.unwrap_or(4096),
            supports_streaming: false,
            supports_functions: false,
        }
    }

    fn validate_config(&self) -> Result<()> {
        if self.api_key.is_empty() {
            return Err(AgentMemError::config_error("Claude API key is required"));
        }
        Ok(())
    }


}

#[cfg(test)]
mod tests {
    use super::*;
    use agent_mem_traits::{MessageRole, LLMProvider};

    fn create_test_config() -> LLMConfig {
        LLMConfig {
            provider: "claude".to_string(),
            model: "claude-3-haiku-20240307".to_string(),
            api_key: Some("test-key".to_string()),
            base_url: Some("https://api.anthropic.com".to_string()),
            max_tokens: Some(1000),
            temperature: Some(0.7),
            top_p: Some(0.9),
            frequency_penalty: None,
            presence_penalty: None,
            response_format: None,
        }
    }

    #[test]
    fn test_claude_provider_creation() {
        let config = create_test_config();
        let provider = ClaudeProvider::new(config);
        assert!(provider.is_ok());
    }
    
    #[test]
    fn test_available_models() {
        let models = ClaudeProvider::available_models();
        assert!(!models.is_empty());
        assert!(models.contains(&"claude-3-5-sonnet-20241022"));
        assert!(models.contains(&"claude-3-opus-20240229"));
    }
    
    #[test]
    fn test_message_conversion() {
        let config = create_test_config();
        let provider = ClaudeProvider::new(config).unwrap();
        
        let message = Message {
            role: MessageRole::User,
            content: "Hello, Claude!".to_string(),
            timestamp: None, // No timestamp for testing
        };
        
        let claude_message = provider.convert_message(&message);
        assert_eq!(claude_message.role, "user");
        assert_eq!(claude_message.content, "Hello, Claude!");
    }
    
    #[test]
    fn test_request_building() {
        let config = create_test_config();
        let provider = ClaudeProvider::new(config).unwrap();
        
        let messages = vec![
            Message {
                role: MessageRole::System,
                content: "You are a helpful assistant.".to_string(),
                timestamp: None,
            },
            Message {
                role: MessageRole::User,
                content: "Hello!".to_string(),
                timestamp: None,
            },
        ];
        
        let request = provider.build_request(&messages).unwrap();
        assert_eq!(request.model, "claude-3-haiku-20240307");
        assert_eq!(request.system, Some("You are a helpful assistant.".to_string()));
        assert_eq!(request.messages.len(), 1);
        assert_eq!(request.messages[0].role, "user");
    }
    
    #[test]
    fn test_model_info() {
        let config = create_test_config();
        let provider = ClaudeProvider::new(config).unwrap();
        
        let info = provider.get_model_info();
        assert_eq!(info.provider, "anthropic");
        assert_eq!(info.model, "claude-3-haiku-20240307");
        assert_eq!(info.max_tokens, 1000);
        assert!(!info.supports_streaming);
    }
}
